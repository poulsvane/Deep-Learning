from lxml import html
import requests


#Collects hyperlinks from the front page of www.denstoredanske.dk, from the most active currently, daily, and weekly. 
def starter():
    link = "http://denstoredanske.dk/"
    page = requests.get(link)
    tree = html.fromstring(page.content)
    k = tree.xpath('//div[@class="icon badge-10 cols-3"]//@href')
    return(k)

#Scrapes the main body text and hyperlinks from articles from www.denstoredanske.dk.
def denstore(x):
    page = requests.get(x)
    tree = html.fromstring(page.content)
    texts = tree.xpath('//div[@class="body-content"]/div[@id]/p//text()|//div[@class="body-content"]/p//text()')
    links = tree.xpath('//div[@class="body-content"]/div[@id]/p//@href|//div[@class="body-content"]/p//@href')
    return(texts, links)

def getlinks(x):
    page = requests.get(x)
    tree = html.fromstring(page.content)
    links = tree.xpath('//div[@class="body-content"]/div[@id]/p//@href|//div[@class="body-content"]/p//@href')
    return(links)
    
def gettext(x):
    page = requests.get(x)
    tree = html.fromstring(page.content)
    texts = tree.xpath('//div[@class="body-content"]/div[@id]/p//text()|//div[@class="body-content"]/p//text()')
    return(texts)
    
def vraps(x):
    checked = []
    #get starter
    links = set(starter())
    #itterate over desired recursions
    for k in range(x):
        #clean list of checked links
        listtoget = [z for z in links if z not in checked]
        #get links from unchecked sites and extend the checked list
        for i in listtoget:
            n = getlinks(i)
            links.update(n)
            checked.append(i)
    return(links)
    

def forkortelser():
    x = "https://syntaksis.dk/forkortelser/"
    page = requests.get(x)
    tree = html.fromstring(page.content)
    shorts_1 = tree.xpath('//td[@class="column-1"]/text()')
    shorts_1_1 = [x.split("(") for x in shorts_1]
    result = [val.replace(")", "") for sublist in shorts_1_1 for val in sublist]
    
    x = "http://www.grafisk-litteratur.dk/?id=16"
    page = requests.get(x)
    tree = html.fromstring(page.content)
    shorts_2 = tree.xpath('//div[@class="forkortelse"]/text()')
    #for i in shorts_2
    
    shorts = result
    return(shorts)
    
    



#Recursively collects text and links from the previous itterations collected links.
#If we need more data, add another block.
"""
text = [] 
links_1 = starter()

links_2 = []   
for i in links_1:
    a,b = denstore(i)
    text.append(a)
    links_2.append(b)
    
links_3 = []
for i in links_2:
    a,b = denstore(i)
    text.append(a)
    links_3.append(b)
"""
